{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Insincere Questions Classification\n",
    "#### Aleix Casellas Comas, Rubén Barco Terrones, Andreu Masdeu Ninot, Pablo Lázaro Terrones, Marco Gani Remane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruben\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "import multiprocessing\n",
    "import gensim.models.word2vec as w2v\n",
    "import os\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>000075f67dd595c3deb5</td>\n",
       "      <td>What can you say about feminism?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>000076f3b42776c692de</td>\n",
       "      <td>How were the Calgary Flames founded?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>000089792b3fc8026741</td>\n",
       "      <td>What is the dumbest, yet possibly true explana...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>000092a90bcfbfe8cd88</td>\n",
       "      <td>Can we use our external hard disk as a OS as w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>000095680e41a9a6f6e3</td>\n",
       "      <td>I am 30, living at home and have no boyfriend....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0000a89942e3143e333a</td>\n",
       "      <td>What do you know about Bram Fischer and the Ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0000b8e1279eaa0a7062</td>\n",
       "      <td>How difficult is it to find a good instructor ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0000bc0f62500f55959f</td>\n",
       "      <td>Have you licked the skin of a corpse?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0000ce6c31f14d3e09ec</td>\n",
       "      <td>Do you think Amazon will adopt an in house app...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0000d329332845b8a7fa</td>\n",
       "      <td>How many baronies might exist within a county ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0000dd973dfd35508c16</td>\n",
       "      <td>How I know whether a girl had done sex before ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0000e4d455f9c8877dc9</td>\n",
       "      <td>How do I become a fast learner both in my prof...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0000e91571b60c2fb487</td>\n",
       "      <td>Has the United States become the largest dicta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>000101ac65db6e4a1c13</td>\n",
       "      <td>What is the strangest phenomenon you know of, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00010632971fe5e3e0e2</td>\n",
       "      <td>Should I leave my friends and find new ones?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00010a2e064c3e8f152a</td>\n",
       "      <td>Can you make Amazon Alexa trigger events in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00012011b6c7759461e8</td>\n",
       "      <td>Why haven't two democracies never ever went fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00012fd5128d576260ab</td>\n",
       "      <td>How can I top CBSE in 6 months?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0001303b1799a042b26b</td>\n",
       "      <td>What should I know before visiting Mcleodganj ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00013a8152b5f37b780e</td>\n",
       "      <td>How do modern military submarines reduce noise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306089</th>\n",
       "      <td>fffeaee9356b09078753</td>\n",
       "      <td>I hardly talk about my interests (reading and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306090</th>\n",
       "      <td>fffeba722d9b371bd1b9</td>\n",
       "      <td>How is it to have intimate relation with your ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306091</th>\n",
       "      <td>fffee269360dd0d3947a</td>\n",
       "      <td>Why is it when singers have lyrics about voice...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306092</th>\n",
       "      <td>fffee78cd374c14d15f8</td>\n",
       "      <td>Does the ginger plant naturally contain sugar?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306093</th>\n",
       "      <td>fffef2de11d291406fdb</td>\n",
       "      <td>Are technological advances in medicine doing m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306094</th>\n",
       "      <td>fffef6ecdfd410ddd5c0</td>\n",
       "      <td>Can I pass class 11 math if I have 85 marks ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306095</th>\n",
       "      <td>ffff0e0bad740a698663</td>\n",
       "      <td>Do you think that the physical traits you are ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306096</th>\n",
       "      <td>ffff0e4ea1bb6e16feec</td>\n",
       "      <td>Do pakis smell of curry and shit?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306097</th>\n",
       "      <td>ffff265faac66b6085da</td>\n",
       "      <td>On Quora is it as good as downvoting the answe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306098</th>\n",
       "      <td>ffff2adc1895bc0c32e1</td>\n",
       "      <td>Are the Wahabis Muslim's puritans?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306099</th>\n",
       "      <td>ffff3778790af9baae76</td>\n",
       "      <td>What steps can I take to live a normal life if...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306100</th>\n",
       "      <td>ffff3f0a2449ffe4b9ff</td>\n",
       "      <td>Isn't Trump right after all? Why should the US...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306101</th>\n",
       "      <td>ffff41393389d4206066</td>\n",
       "      <td>Is 33 too late for a career in creative advert...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306102</th>\n",
       "      <td>ffff42493fc203cd9532</td>\n",
       "      <td>What is difference between the filteration wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306103</th>\n",
       "      <td>ffff48dd47bee89fff79</td>\n",
       "      <td>If the universe \"popped\" into existence from n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306104</th>\n",
       "      <td>ffff5fd051a032f32a39</td>\n",
       "      <td>How does a shared service technology team meas...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306105</th>\n",
       "      <td>ffff6d528040d3888b93</td>\n",
       "      <td>How is DSATM civil engineering?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306106</th>\n",
       "      <td>ffff8776cd30cdc8d7f8</td>\n",
       "      <td>Do you know any problem that depends solely on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306107</th>\n",
       "      <td>ffff94d427ade3716cd1</td>\n",
       "      <td>What are some comic ideas for you Tube videos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306108</th>\n",
       "      <td>ffffa382c58368071dc9</td>\n",
       "      <td>If you had $10 million of Bitcoin, could you s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306109</th>\n",
       "      <td>ffffa5b0fa76431c063f</td>\n",
       "      <td>Are you ashamed of being an Indian?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306110</th>\n",
       "      <td>ffffae5dbda3dc9e9771</td>\n",
       "      <td>What are the methods to determine fossil ages ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306111</th>\n",
       "      <td>ffffba7c4888798571c1</td>\n",
       "      <td>What is your story today?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306112</th>\n",
       "      <td>ffffc0c7158658a06fd9</td>\n",
       "      <td>How do I consume 150 gms protein daily both ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306113</th>\n",
       "      <td>ffffc404da586ac5a08f</td>\n",
       "      <td>What are the good career options for a msc che...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306114</th>\n",
       "      <td>ffffcc4e2331aaf1e41e</td>\n",
       "      <td>What other technical skills do you need as a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306115</th>\n",
       "      <td>ffffd431801e5a2f4861</td>\n",
       "      <td>Does MS in ECE have good job prospects in USA ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306116</th>\n",
       "      <td>ffffd48fb36b63db010c</td>\n",
       "      <td>Is foam insulation toxic?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306117</th>\n",
       "      <td>ffffec519fa37cf60c78</td>\n",
       "      <td>How can one start a research project based on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306118</th>\n",
       "      <td>ffffed09fedb5088744a</td>\n",
       "      <td>Who wins in a battle between a Wolverine and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1306119 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          qid  \\\n",
       "0        00002165364db923c7e6   \n",
       "1        000032939017120e6e44   \n",
       "2        0000412ca6e4628ce2cf   \n",
       "3        000042bf85aa498cd78e   \n",
       "4        0000455dfa3e01eae3af   \n",
       "5        00004f9a462a357c33be   \n",
       "6        00005059a06ee19e11ad   \n",
       "7        0000559f875832745e2e   \n",
       "8        00005bd3426b2d0c8305   \n",
       "9        00006e6928c5df60eacb   \n",
       "10       000075f67dd595c3deb5   \n",
       "11       000076f3b42776c692de   \n",
       "12       000089792b3fc8026741   \n",
       "13       000092a90bcfbfe8cd88   \n",
       "14       000095680e41a9a6f6e3   \n",
       "15       0000a89942e3143e333a   \n",
       "16       0000b8e1279eaa0a7062   \n",
       "17       0000bc0f62500f55959f   \n",
       "18       0000ce6c31f14d3e09ec   \n",
       "19       0000d329332845b8a7fa   \n",
       "20       0000dd973dfd35508c16   \n",
       "21       0000e4d455f9c8877dc9   \n",
       "22       0000e91571b60c2fb487   \n",
       "23       000101ac65db6e4a1c13   \n",
       "24       00010632971fe5e3e0e2   \n",
       "25       00010a2e064c3e8f152a   \n",
       "26       00012011b6c7759461e8   \n",
       "27       00012fd5128d576260ab   \n",
       "28       0001303b1799a042b26b   \n",
       "29       00013a8152b5f37b780e   \n",
       "...                       ...   \n",
       "1306089  fffeaee9356b09078753   \n",
       "1306090  fffeba722d9b371bd1b9   \n",
       "1306091  fffee269360dd0d3947a   \n",
       "1306092  fffee78cd374c14d15f8   \n",
       "1306093  fffef2de11d291406fdb   \n",
       "1306094  fffef6ecdfd410ddd5c0   \n",
       "1306095  ffff0e0bad740a698663   \n",
       "1306096  ffff0e4ea1bb6e16feec   \n",
       "1306097  ffff265faac66b6085da   \n",
       "1306098  ffff2adc1895bc0c32e1   \n",
       "1306099  ffff3778790af9baae76   \n",
       "1306100  ffff3f0a2449ffe4b9ff   \n",
       "1306101  ffff41393389d4206066   \n",
       "1306102  ffff42493fc203cd9532   \n",
       "1306103  ffff48dd47bee89fff79   \n",
       "1306104  ffff5fd051a032f32a39   \n",
       "1306105  ffff6d528040d3888b93   \n",
       "1306106  ffff8776cd30cdc8d7f8   \n",
       "1306107  ffff94d427ade3716cd1   \n",
       "1306108  ffffa382c58368071dc9   \n",
       "1306109  ffffa5b0fa76431c063f   \n",
       "1306110  ffffae5dbda3dc9e9771   \n",
       "1306111  ffffba7c4888798571c1   \n",
       "1306112  ffffc0c7158658a06fd9   \n",
       "1306113  ffffc404da586ac5a08f   \n",
       "1306114  ffffcc4e2331aaf1e41e   \n",
       "1306115  ffffd431801e5a2f4861   \n",
       "1306116  ffffd48fb36b63db010c   \n",
       "1306117  ffffec519fa37cf60c78   \n",
       "1306118  ffffed09fedb5088744a   \n",
       "\n",
       "                                             question_text  target  \n",
       "0        How did Quebec nationalists see their province...       0  \n",
       "1        Do you have an adopted dog, how would you enco...       0  \n",
       "2        Why does velocity affect time? Does velocity a...       0  \n",
       "3        How did Otto von Guericke used the Magdeburg h...       0  \n",
       "4        Can I convert montra helicon D to a mountain b...       0  \n",
       "5        Is Gaza slowly becoming Auschwitz, Dachau or T...       0  \n",
       "6        Why does Quora automatically ban conservative ...       0  \n",
       "7        Is it crazy if I wash or wipe my groceries off...       0  \n",
       "8        Is there such a thing as dressing moderately, ...       0  \n",
       "9        Is it just me or have you ever been in this ph...       0  \n",
       "10                        What can you say about feminism?       0  \n",
       "11                    How were the Calgary Flames founded?       0  \n",
       "12       What is the dumbest, yet possibly true explana...       0  \n",
       "13       Can we use our external hard disk as a OS as w...       0  \n",
       "14       I am 30, living at home and have no boyfriend....       0  \n",
       "15       What do you know about Bram Fischer and the Ri...       0  \n",
       "16       How difficult is it to find a good instructor ...       0  \n",
       "17                   Have you licked the skin of a corpse?       0  \n",
       "18       Do you think Amazon will adopt an in house app...       0  \n",
       "19       How many baronies might exist within a county ...       0  \n",
       "20       How I know whether a girl had done sex before ...       0  \n",
       "21       How do I become a fast learner both in my prof...       0  \n",
       "22       Has the United States become the largest dicta...       1  \n",
       "23       What is the strangest phenomenon you know of, ...       0  \n",
       "24            Should I leave my friends and find new ones?       0  \n",
       "25       Can you make Amazon Alexa trigger events in th...       0  \n",
       "26       Why haven't two democracies never ever went fo...       0  \n",
       "27                         How can I top CBSE in 6 months?       0  \n",
       "28       What should I know before visiting Mcleodganj ...       0  \n",
       "29       How do modern military submarines reduce noise...       0  \n",
       "...                                                    ...     ...  \n",
       "1306089  I hardly talk about my interests (reading and ...       0  \n",
       "1306090  How is it to have intimate relation with your ...       1  \n",
       "1306091  Why is it when singers have lyrics about voice...       1  \n",
       "1306092     Does the ginger plant naturally contain sugar?       0  \n",
       "1306093  Are technological advances in medicine doing m...       0  \n",
       "1306094  Can I pass class 11 math if I have 85 marks ou...       0  \n",
       "1306095  Do you think that the physical traits you are ...       0  \n",
       "1306096                  Do pakis smell of curry and shit?       1  \n",
       "1306097  On Quora is it as good as downvoting the answe...       0  \n",
       "1306098                 Are the Wahabis Muslim's puritans?       0  \n",
       "1306099  What steps can I take to live a normal life if...       0  \n",
       "1306100  Isn't Trump right after all? Why should the US...       1  \n",
       "1306101  Is 33 too late for a career in creative advert...       0  \n",
       "1306102  What is difference between the filteration wor...       0  \n",
       "1306103  If the universe \"popped\" into existence from n...       0  \n",
       "1306104  How does a shared service technology team meas...       0  \n",
       "1306105                    How is DSATM civil engineering?       0  \n",
       "1306106  Do you know any problem that depends solely on...       0  \n",
       "1306107  What are some comic ideas for you Tube videos ...       0  \n",
       "1306108  If you had $10 million of Bitcoin, could you s...       0  \n",
       "1306109                Are you ashamed of being an Indian?       1  \n",
       "1306110  What are the methods to determine fossil ages ...       0  \n",
       "1306111                          What is your story today?       0  \n",
       "1306112  How do I consume 150 gms protein daily both ve...       0  \n",
       "1306113  What are the good career options for a msc che...       0  \n",
       "1306114  What other technical skills do you need as a c...       0  \n",
       "1306115  Does MS in ECE have good job prospects in USA ...       0  \n",
       "1306116                          Is foam insulation toxic?       0  \n",
       "1306117  How can one start a research project based on ...       0  \n",
       "1306118  Who wins in a battle between a Wolverine and a...       0  \n",
       "\n",
       "[1306119 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_data = 'C:/Users/ruben/Documents/Máster Data Science/2º Cuatrimestre/Natural Languaje Processing/ML_for_NLP-master/project_1/quora/'\n",
    "train_data = pd.read_csv(dir_data+'train.csv')\n",
    "train_data = train_data.drop(train_data.index[420816]) #'\"'\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data = train_data.drop(train_data.index[792938]) #'Do '\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "train_data = train_data.drop(train_data.index[995255]) #'W'\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = model_selection.train_test_split(train_data, test_size=0.2, stratify=train_data['target'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044895, 3), (261224, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044895,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train =  X_train['target'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261224,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = X_test['target'].values\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 'How is the writing style and structure in the novel \"Germinal\" by Émile Zola depicted?',\n",
       "        'Is a debtor, a bonded labor? Why',\n",
       "        'What are the best ways to develop leads?', ...,\n",
       "        'Is the discount rate of buying one share of a stock equal to the discount rate of buying ten shares?',\n",
       "        'What is the best way to get a personal loan in Kenya?',\n",
       "        'Do you think a piloted airplane could fly under the Deception Pass Bridge?'], dtype=object),\n",
       " 1044895)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = X_train['question_text'].values\n",
    "x_train, len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['What is the minimum salary required for American Express Card?',\n",
       "        'Can you make French fries only out of russet potatoes?',\n",
       "        'How is the mark vs relative grade at NITC? What would be the pass mark for maths 1 usually? No one has answered this type of question on Quora . How much marks required for each grade?',\n",
       "        ...,\n",
       "        'What is the maximum size Transmission/Front sprocket that can be used for a Bajaj Avenger 220?',\n",
       "        'What should I do if I have a small penis at 15-years-old?',\n",
       "        'In which direction does spiders make its web?'], dtype=object),\n",
       " 261224)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = X_test['question_text'].values\n",
    "x_test, len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(raw):\n",
    "    clean = raw#    clean = re.sub(\"[^a-zA-Z]\",\" \", raw)\n",
    "    clean = clean.lower()\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in x_train:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "for raw_sentence in x_test:\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306119, 1306119)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(x_train)+len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'is',\n",
       " 'the',\n",
       " 'writing',\n",
       " 'style',\n",
       " 'and',\n",
       " 'structure',\n",
       " 'in',\n",
       " 'the',\n",
       " 'novel',\n",
       " '\"germinal\"',\n",
       " 'by',\n",
       " 'émile',\n",
       " 'zola',\n",
       " 'depicted?']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The book corpus contains 16,723,073 tokens\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"The book corpus contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec - 10 epochs / 300 features\n",
    "### Train word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "num_epochs   = 10\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 0\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 3\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "seed = 1\n",
    "\n",
    "#optional Training algorithm: 1 for skip-gram; otherwise CBOW\n",
    "sg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = w2v.Word2Vec(\n",
    "    sg=sg,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec.build_vocab(sentences, keep_raw_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306119"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450473"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.vocabulary.raw_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_examples = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(124297292, 167230730)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word2vec.train(sentences,\n",
    "               epochs = num_epochs,\n",
    "               total_examples=total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foldername = \"C:/Users/ruben/Documents/Máster Data Science/2º Cuatrimestre/Natural Languaje Processing/ML_for_NLP-master/project_1/quora/saved_models/\" + \"w2v_\" + str(num_features) +\"features_\"+ str(context_size) +\"contextsize_\"+str(num_epochs)+\"epochs\"\n",
    "modelname  = \"word2vec_\" + str(num_features) +\"features\"+ str(context_size) +\"contextsize\"+ str(num_epochs)+\"epochs.w2v\"\n",
    "\n",
    "if not os.path.exists(foldername):\n",
    "    os.makedirs(foldername)\n",
    "    word2vec.save(os.path.join(foldername, modelname))\n",
    "else:\n",
    "    print(\"folder {} already exists\".format(foldername))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting from a Word2vec averaged representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_to_vec(sentence, word2vec):\n",
    "    word_list    = sentence_to_wordlist(sentence)\n",
    "    word_vectors = []\n",
    "    for w in word_list:\n",
    "        word_vectors.append(word2vec.wv.get_vector(w))\n",
    "\n",
    "    return np.mean(word_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = np.zeros((len(x_train), num_features))\n",
    "y_tr = y_train\n",
    "n_samples = X_tr.shape[0]\n",
    "\n",
    "for i in range(n_samples):\n",
    "    X_tr[i,:] = doc_to_vec(x_train[i], word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_tr[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_te = np.zeros((len(x_test), num_features))\n",
    "y_te = y_test\n",
    "n_samples = X_te.shape[0]\n",
    "for i in range(n_samples):\n",
    "    X_te[i,:] = doc_to_vec(x_test[i], word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044895, 300), (261224, 300))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with a Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9466252589973155\n",
      "Train F1 score: 0.4246794375844603\n",
      "Test accuracy: 0.9465056809481518\n",
      "Test F1 score: 0.42394261686866186\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_tr)\n",
    "print('Train accuracy: {}'.format(accuracy_score(y_tr, y_pred)))\n",
    "print('Train F1 score: {}'.format(f1_score(y_tr, y_pred)))\n",
    "\n",
    "y_pred = logreg.predict(X_te)\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_te, y_pred)))\n",
    "print('Test F1 score: {}'.format(f1_score(y_te, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec - 20 epochs / 300 features\n",
    "### Train word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "num_epochs   = 20\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 0\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#0 - 1e-5 is good for this\n",
    "downsampling = 1e-3\n",
    "\n",
    "seed = 1\n",
    "\n",
    "#optional Training algorithm: 1 for skip-gram; otherwise CBOW\n",
    "sg = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = w2v.Word2Vec(\n",
    "    sg=sg,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec.build_vocab(sentences, keep_raw_vocab=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306119"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450473"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2vec.vocabulary.raw_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_examples = len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(248592853, 334461460)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "word2vec.train(sentences,\n",
    "               epochs = num_epochs,\n",
    "               total_examples=total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foldername = \"C:/Users/ruben/Documents/Máster Data Science/2º Cuatrimestre/Natural Languaje Processing/ML_for_NLP-master/project_1/quora/saved_models/\" + \"w2v_\" + str(num_features) +\"features_\"+ str(context_size) +\"contextsize_\"+str(num_epochs)+\"epochs\"\n",
    "modelname  = \"word2vec_\" + str(num_features) +\"features\"+ str(context_size) +\"contextsize\"+ str(num_epochs)+\"epochs.w2v\"\n",
    "\n",
    "if not os.path.exists(foldername):\n",
    "    os.makedirs(foldername)\n",
    "    word2vec.save(os.path.join(foldername, modelname))\n",
    "else:\n",
    "    print(\"folder {} already exists\".format(foldername))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting from a Word2vec averaged representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def doc_to_vec(sentence, word2vec):\n",
    "    word_list    = sentence_to_wordlist(sentence)\n",
    "    word_vectors = []\n",
    "    for w in word_list:\n",
    "        word_vectors.append(word2vec.wv.get_vector(w))\n",
    "\n",
    "    return np.mean(word_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr = np.zeros((len(x_train), num_features))\n",
    "y_tr = y_train\n",
    "n_samples = X_tr.shape[0]\n",
    "\n",
    "for i in range(n_samples):\n",
    "    X_tr[i,:] = doc_to_vec(x_train[i], word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_te = np.zeros((len(x_test), num_features))\n",
    "y_te = y_test\n",
    "n_samples = X_te.shape[0]\n",
    "for i in range(n_samples):\n",
    "    X_te[i,:] = doc_to_vec(x_test[i], word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044895, 300), (261224, 300))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting with a Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9472128778489705\n",
      "Train F1 score: 0.4375121100561907\n",
      "Test accuracy: 0.9468884941659266\n",
      "Test F1 score: 0.43546549479166663\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_tr)\n",
    "print('Train accuracy: {}'.format(accuracy_score(y_tr, y_pred)))\n",
    "print('Train F1 score: {}'.format(f1_score(y_tr, y_pred)))\n",
    "\n",
    "y_pred = logreg.predict(X_te)\n",
    "print('Test accuracy: {}'.format(accuracy_score(y_te, y_pred)))\n",
    "print('Test F1 score: {}'.format(f1_score(y_te, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
