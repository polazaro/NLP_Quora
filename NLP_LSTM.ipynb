{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Insincere Questions Classification\n",
    "#### Aleix Casellas Comas, Rubén Barco Terrones, Andreu Masdeu Ninot, Pablo Lázaro Terrones, Marco Gani Remane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\andre\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import keras, nltk, os, matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Embedding, Input, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers import LSTM, Bidirectional, GlobalMaxPool1D, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_data = 'C:/Users/andre/Documents/Master/NLP assigments/'\n",
    "train_data = pd.read_csv(dir_data+'train.csv')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(train_data, test_size=0.2, stratify=train_data['target'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044897, 3), (261225, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044897,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train =  X_train['target'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261225,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = X_test['target'].values\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train['question_text'].values\n",
    "X_test = X_test['question_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = get_stop_words('english')\n",
    "punctuation = ['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}','?',\"''\"]\n",
    "\n",
    "## Keep appending stop words it they are detected\n",
    "# I'll: we remove 'll, it's: remove 's, can't: remove 't\n",
    "stop_words.extend(['\\'ll', '\\'s', '\\'t', '``','n\\'t'])\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "snow  = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swimming'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem.lemmatize('swimming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'swim'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('swimming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(v):\n",
    "    tokens = word_tokenize(v)\n",
    "\n",
    "    filtered = [word.lower() for word in tokens if word.lower() not in stop_words and word not in punctuation and len(word) < 25]\n",
    "    v2 = filtered\n",
    "    v3 = []\n",
    "    for elem in v2:\n",
    "        #v3.append(elem)\n",
    "        v3.append(snow.stem(elem)) # To use if you wished to apply stemming\n",
    "    str1 = ' '.join(v3)\n",
    "    return str1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "for i in range(0,len(X_train)):\n",
    "    train.append(filtering(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = []\n",
    "for i in range(0,len(X_test)):\n",
    "    test.append(filtering(X_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = 20000\n",
    "tokenizer = text.Tokenizer(num_words = n_words, filters='\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train+test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintok = tokenizer.texts_to_sequences(train)\n",
    "testtok = tokenizer.texts_to_sequences(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n"
     ]
    }
   ],
   "source": [
    "maxlen = 0\n",
    "lengths = []\n",
    "for x in traintok:\n",
    "    length = len(x)\n",
    "    lengths.append(length)\n",
    "    if length > maxlen:\n",
    "        maxlen = length\n",
    "\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(lengths, bins = 10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 25\n",
    "\n",
    "X_t = sequence.pad_sequences(traintok, maxlen=maxlen)\n",
    "X_te = sequence.pad_sequences(testtok, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_model(nhid = 2, drop = 0.1 , recdrop = 0.1, units = 50, drop2 = 0):\n",
    "    model = Sequential()\n",
    "    leaky = keras.layers.LeakyReLU(alpha=0.05)\n",
    "    model.add(Embedding( n_words , 128, input_length=maxlen, trainable = True))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=True, dropout=drop, recurrent_dropout=recdrop)))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    \n",
    "    for i in range(0,nhid):\n",
    "        model.add(Dense(int(128/(2 ** i))))\n",
    "        model.add(leaky)\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout (drop2))\n",
    "\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = text_model(units = 50, nhid = 1, drop = 0.1, recdrop = 0.1, drop2 = 0.1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 25, 100)           71600     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,645,169\n",
      "Trainable params: 2,644,913\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1044897 samples, validate on 261225 samples\n",
      "Epoch 1/2\n",
      "1044897/1044897 [==============================] - 2514s 2ms/step - loss: 0.1278 - acc: 0.9500 - val_loss: 0.1261 - val_acc: 0.9492\n",
      "Epoch 2/2\n",
      "1044897/1044897 [==============================] - 3251s 3ms/step - loss: 0.1133 - acc: 0.9556 - val_loss: 0.1138 - val_acc: 0.9553\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_t, y_train, batch_size = 32, epochs = 2, callbacks = [], \n",
    "                    validation_data = (X_te, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"lstm_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"lstm_2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[241733,   8357],\n",
       "       [  3330,   7805]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.round(model.predict(X_te).reshape(-1)).astype(int), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prediction(threshold):\n",
    "    \n",
    "    preds = model.predict(X_te).reshape(-1)\n",
    "    \n",
    "    new_preds = []\n",
    "    \n",
    "    for pred in preds:\n",
    "        \n",
    "        if pred > threshold:\n",
    "            \n",
    "            new_preds.append(1)\n",
    "        else:\n",
    "            new_preds.append(0)\n",
    "    \n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With threshold 0.2 we have F1 Score: 0.6099245615753894\n",
      "With threshold 0.25 we have F1 Score: 0.6227402473834444\n",
      "With threshold 0.3 we have F1 Score: 0.6290952300118825\n",
      "With threshold 0.35 we have F1 Score: 0.6279321544568748\n",
      "With threshold 0.39999999999999997 we have F1 Score: 0.6162096204482692\n",
      "With threshold 0.44999999999999996 we have F1 Score: 0.5979338984795964\n",
      "With threshold 0.49999999999999994 we have F1 Score: 0.571857713301828\n",
      "With threshold 0.5499999999999999 we have F1 Score: 0.5343799058084773\n",
      "With threshold 0.5999999999999999 we have F1 Score: 0.4868348991026667\n",
      "With threshold 0.6499999999999999 we have F1 Score: 0.4238968092328581\n",
      "With threshold 0.7 we have F1 Score: 0.3397615192109525\n",
      "With threshold 0.7499999999999998 we have F1 Score: 0.24419404327355448\n",
      "With threshold 0.7999999999999998 we have F1 Score: 0.14010129175439595\n"
     ]
    }
   ],
   "source": [
    "for threshold in np.arange(0.2, 0.8, 0.05):\n",
    "    \n",
    "    f1 = f1_score(lstm_prediction(threshold), y_test)\n",
    "    print(\"With threshold {} we have F1 Score: {}\".format(threshold, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.571857713301828"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.round(model.predict(X_te).reshape(-1)).astype(int), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6235073198300851"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(np.round(model.predict(X_t).reshape(-1)).astype(int), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000163e3ea7c7a74cd7</td>\n",
       "      <td>Why do so many women become so rude and arroga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00002bd4fb5d505b9161</td>\n",
       "      <td>When should I apply for RV college of engineer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00007756b4a147d2b0b3</td>\n",
       "      <td>What is it really like to be a nurse practitio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000086e4b7e1c7146103</td>\n",
       "      <td>Who are entrepreneurs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000c4c3fbe8785a3090</td>\n",
       "      <td>Is education really making good people nowadays?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n",
       "1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n",
       "2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n",
       "3  000086e4b7e1c7146103                             Who are entrepreneurs?\n",
       "4  0000c4c3fbe8785a3090   Is education really making good people nowadays?"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_data = 'C:/Users/andre/Documents/Master/NLP assigments/'\n",
    "test_data = pd.read_csv(dir_data+'test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle = test_data['question_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kaggle = []\n",
    "for i in range(0,len(X_kaggle)):\n",
    "    test_kaggle.append(filtering(X_kaggle[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testkaggletok = tokenizer.texts_to_sequences(test_kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kg = sequence.pad_sequences(testkaggletok, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preds.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(preds).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['qid'] = test_data['qid']\n",
    "submission['prediction'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
