{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quora Insincere Questions Classification\n",
    "#### Aleix Casellas Comas, Rubén Barco Terrones, Andreu Masdeu Ninot, Pablo Lázaro Terrones, Marco Gani Remane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL\n",
    "#### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dir_data = 'D:/Data_Master/Natural Language Processing/Project1/quora/'\n",
    "#train_data = pd.read_csv(dir_data+'train.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = model_selection.train_test_split(train_data, test_size=0.2, stratify=train_data['target'], random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1044897, 3), (261225, 3))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044897,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train =  X_train['target'].values\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261225,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = X_test['target'].values\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['How will the United States deal with record low unemployment?',\n",
       "        'How long have the moderators on Quora been deciding that comments don\\'t meet the \"Be Nice\" policy simply because they disagree with the political opinion, apparently?',\n",
       "        'When does the learning curve in C++ go steep?', ...,\n",
       "        'Is the discount rate of buying one share of a stock equal to the discount rate of buying ten shares?',\n",
       "        'What is the best way to get a personal loan in Kenya?',\n",
       "        'Do you think a piloted airplane could fly under the Deception Pass Bridge?'],\n",
       "       dtype=object), 1044897)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = X_train['question_text'].values\n",
    "x_train, len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['What is the minimum salary required for American Express Card?',\n",
       "        'Can you make French fries only out of russet potatoes?',\n",
       "        'How is the mark vs relative grade at NITC? What would be the pass mark for maths 1 usually? No one has answered this type of question on Quora . How much marks required for each grade?',\n",
       "        ...,\n",
       "        'What is the maximum size Transmission/Front sprocket that can be used for a Bajaj Avenger 220?',\n",
       "        'How do liberals feel about Mark Dice absolutely destroying their ideology?',\n",
       "        'In which direction does spiders make its web?'], dtype=object),\n",
       " 261225)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = X_test['question_text'].values\n",
    "x_test, len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the parameters inside the CountVectorizer, for example removing ngram_range or adding stop-words\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(ngram_range=(1,2))\n",
    "x_train_vec = count_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 154278 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(tokenizer=LemmaTokenizer(),ngram_range=(1,2)) \n",
    "x_train_vec = count_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 154278 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "count_vectorizer = sklearn.feature_extraction.text.CountVectorizer(analyzer=stemmed_words,ngram_range=(1,2), stop_words='english')\n",
    "x_train_vec = count_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tfidfvectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(ngram_range=(1,2)) \n",
    "x_train_vec = tfidf_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 140280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(analyzer=stemmed_words,ngram_range=(1,2), stop_words='english') # Try with 2-gram\n",
    "x_train_vec = tfidf_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "\n",
    "tfidf_vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(tokenizer=LemmaTokenizer(),ngram_range=(1,2), stop_words='english') # Try with 2-gram\n",
    "x_train_vec = tfidf_vectorizer.fit_transform(x_train)\n",
    "n_features = x_train_vec.shape[1]\n",
    "min_k = n_features//2\n",
    "# max_k = n_features\n",
    "max_k = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = SelectKBest(chi2)\n",
    "# logistic = sklearn.linear_model.LogisticRegression(C=0.1) #Comment one line or the other depending on the classifier\n",
    "mnb = MultinomialNB()                                       #you want to use\n",
    "pipeline_1 = Pipeline([\n",
    "    (\"count_vectorizer\", count_vectorizer),\n",
    "    (\"feature_selector\", feature_selector),\n",
    "    (\"Naive_Bayes\", mnb),\n",
    "#     (\"logistic_regression\", logistic)\n",
    "])\n",
    "\n",
    "possible_K = [int(x)-1 for x in np.linspace(min_k, max_k,10)]\n",
    "parameteres = {'feature_selector__k':possible_K}#, 'Naive_Bayes__alpha':[0,0.5,1], 'logisticregression__C':[0.1,0.01,0.001]} #You can add these parameters for CV\n",
    "\n",
    "pipeline_2 = sklearn.model_selection.RandomizedSearchCV(pipeline_1,\n",
    "                                                   param_distributions=parameteres, \n",
    "                                                   cv=3,\n",
    "                                                   n_iter=2,\n",
    "                                                   n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 4min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=Pipeline(memory=None,\n",
       "     steps=[('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       " ...ty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False))]),\n",
       "          fit_params=None, iid=True, n_iter=2, n_jobs=1,\n",
       "          param_distributions={'feature_selector__k': [1329389, 1198821, 1068253, 937685, 807117, 676549, 545981, 415413, 284845, 154277]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "pipeline_2.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_selector__k': 1198821}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_train=0.9657554763770975 acc_test=0.9555555555555556\n",
      "f1_train=0.6673051175245462 f1_test=0.554489639293937\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = pipeline_2.predict(x_train)\n",
    "y_test_pred = pipeline_2.predict(x_test)\n",
    "acc_train = np.mean(y_train_pred == y_train)\n",
    "acc_test = np.mean(y_test_pred == y_test)\n",
    "print(\"acc_train={} acc_test={}\".format(acc_train, acc_test))\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "print(\"f1_train={} f1_test={}\".format(f1_train, f1_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with the real test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00004f9a462a357c33be</td>\n",
       "      <td>Is Gaza slowly becoming Auschwitz, Dachau or T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00005059a06ee19e11ad</td>\n",
       "      <td>Why does Quora automatically ban conservative ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0000559f875832745e2e</td>\n",
       "      <td>Is it crazy if I wash or wipe my groceries off...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00005bd3426b2d0c8305</td>\n",
       "      <td>Is there such a thing as dressing moderately, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00006e6928c5df60eacb</td>\n",
       "      <td>Is it just me or have you ever been in this ph...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "5  00004f9a462a357c33be  Is Gaza slowly becoming Auschwitz, Dachau or T...   \n",
       "6  00005059a06ee19e11ad  Why does Quora automatically ban conservative ...   \n",
       "7  0000559f875832745e2e  Is it crazy if I wash or wipe my groceries off...   \n",
       "8  00005bd3426b2d0c8305  Is there such a thing as dressing moderately, ...   \n",
       "9  00006e6928c5df60eacb  Is it just me or have you ever been in this ph...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "5       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  \n",
       "9       0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir_data = 'D:/Data_Master/Natural Language Processing/Project1/quora/'\n",
    "# X_test_2 = pd.read_csv(dir_data+'test.csv')\n",
    "X_test_2 = pd.read_csv('test.csv')\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Why do so many women become so rude and arrogant when they get just a little bit of wealth and power?',\n",
       "        'When should I apply for RV college of engineering and BMS college of engineering? Should I wait for the COMEDK result or am I supposed to apply before the result?',\n",
       "        'What is it really like to be a nurse practitioner?', ...,\n",
       "        'Where I can find best friendship quotes in Telugu?',\n",
       "        'What are the causes of refraction of light?',\n",
       "        \"Climate change is a worrying topic. How much time do we have left to find another planet? I mean, I don't think humans will survive on this earth for another 1000 years.. What do you think?\"],\n",
       "       dtype=object), 375806)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_2 = X_test_2['question_text'].values\n",
    "x_test_2, len(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['why do so many women become so rude and arrogant when they get just a little bit of wealth and power',\n",
       "        'when should i apply for rv college of engineering and bms college of engineering? should i wait for the comedk result or am i supposed to apply before the result',\n",
       "        'what is it really like to be a nurse practitioner', ...,\n",
       "        'where i can find best friendship quotes in telugu',\n",
       "        'what are the causes of refraction of light',\n",
       "        \"climate change is a worrying topic. how much time do we have left to find another planet? i mean, i don't think humans will survive on this earth for another 1000 years.. what do you think\"],\n",
       "       dtype=object), 375806)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(x_test_2[:])):\n",
    "    x_test_2[i] = x_test_2[i][:-1].lower()\n",
    "x_test_2, len(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline_2.predict(x_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2['prediction'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = X_test_2.drop(columns=\"question_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
